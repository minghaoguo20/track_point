{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打开视频文件\n",
    "video_path = \"/mnt/data/minghao/EPIC-KITCHENS/P06/videos/P02_109.MP4\"\n",
    "video_path = \"/data/minghao/dataset/demo/P02_109.MP4\"\n",
    "video_path = \"/data/minghao/dataset/demo/P28_12.MP4\"\n",
    "output_dir = \"/home/minghao/code/vlm/molmo/demo_output\"\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查视频是否打开成功\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame saved at /home/minghao/code/vlm/molmo/demo_output/P28_12_at_5_seconds.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 获取视频的帧率 (fps)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 获取指定时间（例如：5秒）\n",
    "time_in_seconds = 5\n",
    "\n",
    "# 根据时间计算出帧数\n",
    "frame_number = int(time_in_seconds * fps)\n",
    "\n",
    "# 跳转到指定帧\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "# 读取该帧\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if ret:\n",
    "    file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    output_image_path = os.path.join(output_dir, \"{}_at_{}_seconds.jpg\".format(file_name, time_in_seconds))\n",
    "    cv2.imwrite(output_image_path, frame)\n",
    "    print(f\"Frame saved at {output_image_path}\")\n",
    "else:\n",
    "    print(f\"Error: Could not read frame at {time_in_seconds} seconds\")\n",
    "\n",
    "# 释放资源\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minghao/miniconda3/envs/molmo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPTNeoXTokenizer'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    }
   ],
   "source": [
    "github_model_dir = '/home/minghao/warehouse/molmo/model/Molmo-7B-D-0924'\n",
    "molmo_7b = '/data/minghao/molmo/hf/Molmo-7B-D-0924'\n",
    "molmo_1b = '/data/minghao/molmo/hf/MolmoE-1B-0924'\n",
    "\n",
    "model_dir = molmo_1b\n",
    "\n",
    "# video_path = \"/mnt/data/minghao/EPIC-KITCHENS/P06/videos/P02_109.MP4\"\n",
    "\n",
    "# load the processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_dir, # 'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir, # 'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fork\n"
     ]
    }
   ],
   "source": [
    "# process the image and text\n",
    "# Open the image from the file path\n",
    "inputs = processor.process(\n",
    "    images=[Image.open(output_image_path)],\n",
    "    text=\"What object is the hand holding? Only answer the name of the object.\"\n",
    "    # text=\"Describe this image.\"\n",
    ")\n",
    "\n",
    "# move inputs to the correct device and make a batch of size 1\n",
    "inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "\n",
    "# generate output; maximum 200 new tokens; stop generation when <|endoftext|> is generated\n",
    "output = model.generate_from_batch(\n",
    "    inputs,\n",
    "    GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\"),\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "\n",
    "# only get generated tokens; decode them to text\n",
    "generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "# print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <point x=\"44.0\" y=\"71.9\" alt=\"hand is holding the object\">hand is holding the object</point>\n"
     ]
    }
   ],
   "source": [
    "# process the image and text\n",
    "# Open the image from the file path\n",
    "inputs = processor.process(\n",
    "    images=[Image.open(output_image_path)],\n",
    "    text=\"Point out where the hand is holding the object.\"\n",
    "    # text=\"Describe this image.\"\n",
    ")\n",
    "\n",
    "# move inputs to the correct device and make a batch of size 1\n",
    "inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "\n",
    "# generate output; maximum 200 new tokens; stop generation when <|endoftext|> is generated\n",
    "output = model.generate_from_batch(\n",
    "    inputs,\n",
    "    GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\"),\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n",
    "\n",
    "# only get generated tokens; decode them to text\n",
    "generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "# print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates extracted: x=44.0, y=71.9\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Use regular expression to find the coordinates in the generated_text\n",
    "pattern = r'<point x=\"([\\d.]+)\" y=\"([\\d.]+)\" alt=\"[^\"]+\">[^<]+</point>'\n",
    "match = re.search(pattern, generated_text)\n",
    "\n",
    "if match:\n",
    "    x = float(match.group(1))\n",
    "    y = float(match.group(2))\n",
    "    print(f\"Coordinates extracted: x={x}, y={y}\")\n",
    "else:\n",
    "    print(\"No coordinates found in the generated text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with point saved at /home/minghao/code/vlm/molmo/demo_output/P28_12_with_point.jpg\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "image = cv2.imread(output_image_path)\n",
    "\n",
    "# Convert ratio coordinates to absolute integer values\n",
    "height, width, _ = image.shape\n",
    "x_abs = int(x * width / 100)\n",
    "y_abs = int(y * height / 100)\n",
    "\n",
    "# Draw a circle at the specified coordinates\n",
    "cv2.circle(image, (x_abs, y_abs), radius=5, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "# Define the new output image path\n",
    "new_output_image_path = os.path.join(output_dir, \"{}_with_point.jpg\".format(file_name))\n",
    "\n",
    "# Save the modified image\n",
    "cv2.imwrite(new_output_image_path, image)\n",
    "\n",
    "print(f\"Image with point saved at {new_output_image_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
